# Running Tests and Examples

## Setup

Install dependencies:

```bash
pnpm install
```

## Running Tests

Run all tests:
```bash
pnpm test
```

Run tests in watch mode:
```bash
pnpm test:watch
```

Run tests with coverage:
```bash
pnpm test:coverage
```

## Running the Example

Run the basic agent example:
```bash
pnpm example
```

This will run a simple weather assistant that demonstrates:
- LLM interaction
- Tool calling (weather API)
- Event streaming
- A2A protocol-compliant events

## Test Coverage

The test suite covers:

### Basic Execution
- âœ… Simple completion without tools
- âœ… A2A-compliant event emission
- âœ… Event structure validation

### Tool Execution
- âœ… Single tool call execution
- âœ… Multiple tool calls
- âœ… Tool error handling

### Checkpointing
- âœ… Periodic state checkpointing
- âœ… Resume from checkpoint
- âœ… Resume completed tasks

### Error Handling
- âœ… LLM execution errors
- âœ… Max iteration limits
- âœ… Error event emission

### Context Propagation
- âœ… Trace context propagation
- âœ… Auth context propagation

## Example Output

When you run `pnpm example`, you'll see output like:

```
ğŸš€ Agent Loop Example - Weather Assistant

============================================================

ğŸ“ User Prompt: What is the weather like in Seattle?
============================================================

ğŸ¤– LLM Thinking...
   User: What is the weather like in Seattle?

ğŸ“¡ Event: task
   Task ID: task_1730000000000_abc123
   Context ID: ctx_1730000000000
   Status: submitted

ğŸ“¡ Event: status-update
   Task ID: task_1730000000000_abc123
   Status: working

ğŸ”§ Tool Executing: get_weather
   Arguments: { location: 'Seattle' }
   Result: { location: 'Seattle', temperature: 55, condition: 'rainy', ... }

ğŸ“¡ Event: status-update
   Task ID: task_1730000000000_abc123
   Status: completed
   Message: The weather in Seattle is 55Â°F and rainy. ğŸŒ§ï¸
   âœ… FINAL EVENT

============================================================
âœ… Agent Loop Completed!
============================================================
```

## Test Structure

Tests are organized by functionality:

```
tests/
â””â”€â”€ agent-loop.test.ts
    â”œâ”€â”€ Basic Execution
    â”‚   â”œâ”€â”€ simple completion without tools
    â”‚   â””â”€â”€ A2A-compliant events
    â”œâ”€â”€ Tool Execution
    â”‚   â”œâ”€â”€ single tool call
    â”‚   â”œâ”€â”€ multiple tool calls
    â”‚   â””â”€â”€ error handling
    â”œâ”€â”€ Checkpointing
    â”‚   â”œâ”€â”€ periodic checkpoints
    â”‚   â”œâ”€â”€ resume from checkpoint
    â”‚   â””â”€â”€ resume completed task
    â”œâ”€â”€ Error Handling
    â”‚   â”œâ”€â”€ execution errors
    â”‚   â””â”€â”€ max iterations
    â””â”€â”€ Context Propagation
        â”œâ”€â”€ trace context
        â””â”€â”€ auth context
```

## Example Structure

The example demonstrates:

1. **LLM Provider Implementation** - `SimpleLLMProvider`
   - Simulates OpenAI-style responses
   - Decides when to use tools
   - Generates final responses

2. **Tool Provider Implementation** - `WeatherToolProvider`
   - Provides weather tool definition
   - Simulates weather API calls
   - Returns structured results

3. **Agent Loop Configuration**
   - Sets up providers
   - Configures state storage
   - Enables checkpointing

4. **Event Handling**
   - Subscribes to event stream
   - Logs A2A-compliant events
   - Shows internal events

## Next Steps

After running tests and examples:

1. Review `A2A_ALIGNMENT.md` for event structure details
2. Check `AGENT_LOOP_PROGRESS.md` for implementation status
3. See `PROJECT.md` for design/implementation guidelines
4. Read `design/agent-loop.md` for architecture overview
